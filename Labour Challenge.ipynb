{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re # In-built regular expressions library\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Natural Language Processing Toolkit\n",
    "from nltk.corpus import stopwords, words # get stopwords from NLTK library & get all words in english language\n",
    "from nltk.tokenize import word_tokenize # to create word tokens\n",
    "# from nltk.stem import PorterStemmer (I played around with Stemmer and decided to use Lemmatizer instead)\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\n",
    "from nltk import pos_tag # For Parts of Speech tagging\n",
    "\n",
    "from textblob import TextBlob # TextBlob - Python library for processing textual data\n",
    "\n",
    "# WordCloud - Python linrary for creating image wordclouds\n",
    "from wordcloud import WordCloud\n",
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO # For EMOTICONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971ea80",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d06072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Snscraper to get #labourchallenge tweets by location\n",
    "tweets_lab = pd.DataFrame(sntwitter.TwitterSearchScraper(\n",
    "    '#LabourChallenge since:2022-07-14 until:2022-08-23').get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the locations\n",
    "tweets_lab['user_location'] =  tweets_lab['user'].apply(lambda x: x['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e41edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Snscraper to get #dignityinlabour tweets by location\n",
    "tweets_dig = pd.DataFrame(sntwitter.TwitterSearchScraper(\n",
    "    '#DignityInLabour since:2022-07-14 until:2022-08-23').get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the location\n",
    "tweets_dig['user_location'] =  tweets_dig['user'].apply(lambda x: x['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns in Labour data\n",
    "col=['rawContent','user','retweetCount','likeCount','sourceLabel', 'renderedContent','replyCount','quoteCount','conversationId', 'lang', 'source', 'sourceUrl',\n",
    "         'links','media', 'retweetedTweet', 'quotedTweet', 'inReplyToTweetId','inReplyToUser', 'mentionedUsers',\n",
    "        'cashtags', 'card','url', 'place','hashtags', 'date']\n",
    "tweets_lab.drop(columns=col, inplace=True)\n",
    "tweets_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85471a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns in dignity data\n",
    "col=['rawContent','user','retweetCount','likeCount','sourceLabel', 'renderedContent','replyCount','quoteCount','conversationId', 'lang', 'source', 'sourceUrl',\n",
    "         'links','media', 'retweetedTweet', 'quotedTweet', 'inReplyToTweetId','inReplyToUser', 'mentionedUsers',\n",
    "        'cashtags', 'card','url', 'place','hashtags', 'date']\n",
    "tweets_dig.drop(columns=col, inplace=True)\n",
    "tweets_dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77daa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data to by location - Nigeria\n",
    "data = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#LabourChallenge since:2022-07-14 until:2022-08-23').get_items()):\n",
    "    if i>30000:\n",
    "        break\n",
    "    data.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content, tweet.id, tweet.retweetCount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to load the list\n",
    "df1 = pd.DataFrame(data, columns=[\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\",\"id\",\"Number of Retweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data to by location - Nigeria\n",
    "datas = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#DignityInLabour since:2022-07-14 until:2022-08-23').get_items()):\n",
    "    if i>30000:\n",
    "        break\n",
    "    datas.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content, tweet.id, tweet.retweetCount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to load the list\n",
    "df2 = pd.DataFrame(datas, columns=[\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\",\"id\",\"Number of Retweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data on common column\n",
    "labour=pd.merge(tweets_lab,df1, on='id')\n",
    "print(labour.shape)\n",
    "labour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data on common column\n",
    "dignity=pd.merge(tweets_dig,df2, on='id')\n",
    "print(dignity.shape)\n",
    "dignity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e5e44",
   "metadata": {},
   "source": [
    "## Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a418f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename id, user_location and coordinates columns\n",
    "labour.rename(columns={\"id\" : \"Tweet ID\"}, inplace=True)\n",
    "labour.rename(columns={\"user_location\" : \"Location\"}, inplace=True)\n",
    "labour.rename(columns={\"coordinates\" : \"Coordinates\"}, inplace=True)\n",
    "labour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename id, user_location and coordinates columns\n",
    "dignity.rename(columns={\"id\" : \"Tweet ID\"}, inplace=True)\n",
    "dignity.rename(columns={\"user_location\" : \"Location\"}, inplace=True)\n",
    "dignity.rename(columns={\"coordinates\" : \"Coordinates\"}, inplace=True)\n",
    "dignity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bf469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns\n",
    "cols=['User','Tweet ID','Tweet','Number of Likes','Number of Retweets','Source of Tweet','Location',\n",
    "      'Date Created','Coordinates']\n",
    "labour = labour.reindex(columns=cols)\n",
    "labour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e868a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns\n",
    "cols=['User','Tweet ID','Tweet','Number of Likes','Number of Retweets','Source of Tweet','Location',\n",
    "      'Date Created','Coordinates']\n",
    "dignity = dignity.reindex(columns=cols)\n",
    "dignity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all urls from link\n",
    "labour['Tweet'] = labour['Tweet'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all urls from link\n",
    "dignity['Tweet'] = dignity['Tweet'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a373ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to .csv\n",
    "labour.to_csv('labour.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to .csv\n",
    "dignity.to_csv('dignity.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e7b0b",
   "metadata": {},
   "source": [
    "### Getting Necessary Columns and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a funtion to get all nouns from the texts\n",
    "def getNouns(tweet):\n",
    "    tweet = word_tokenize(tweet)  # convert string to tokens\n",
    "    tweet = [word for (word, tag) in pos_tag(tweet)\n",
    "             if tag == 'NN' or tag == 'NNP' or tag == 'JJ']  # pos_tag module in NLTK library\n",
    "    return \" \".join(tweet)  # join words with a space in between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function\n",
    "text ='#LabourChallenge my name is segun akinsola screeding and painting and pop celling may God bless my ✋ work amen. Pls I need work ooh today is making me 2month and two weeks if you have work for me pls call me 08034653648'\n",
    "getNouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a50dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to a new column in the labour dataframe\n",
    "labour['Processed_Tweets'] = labour['Tweet'].apply(getNouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to a new column in the dignity dataframe\n",
    "dignity['Processed_Tweets'] = dignity['Tweet'].apply(getNouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the processed_tweets column to lowercase\n",
    "labour['Processed_Tweets'] = labour['Processed_Tweets'].str.lower()\n",
    "labour['Processed_Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the processed_tweets column to lowercase\n",
    "dignity['Processed_Tweets'] = dignity['Processed_Tweets'].str.lower()\n",
    "dignity['Processed_Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stop_words and custom words to search for and apply in the Processed_tweets column into a new Career column\n",
    "stop = list(stopwords.words('english'))\n",
    "words= ['engineer', 'farmer','lawyer','manager','baker','caterer','student','painting','software','civil',\n",
    "      'engineer', 'project', 'manager', 'petroleum','making','soap', 'sailor', 'pilot', 'investment', 'dentist',\n",
    "       'software', 'developer', 'accountant','entrepreneur','entrepreneur','designer','designer', 'professional',\n",
    "        'printer', 'trader','paints','legal','freelance','nurse','surgeon','zoologist',\n",
    "      'optometrist','fashion','fashion','fashion designer','guitar','music', 'tech','startup','start-up',\n",
    "      'truck driver','driver','truck','owner','business','market','cook','cooking','pharmacist',\n",
    "       'electrician', 'mechanic', 'machinist','medical', 'doctor','banker','lecturer','lecturer','project manager',\n",
    "       'pharmacist','it', 'security', 'analyst', 'ethical', 'hackers','programmers',\n",
    "       'insurance', 'agent', 'human', 'capital', 'developer','hustler','photographer','craft','borehole', 'technician',\n",
    "       'educator','dealer','dealer','chemical','chemical','photography','business','service','marketer',\n",
    "       'cosmetics','clay','sculptor','clay sculptor','project','graphic designer','graphic','orientator',\n",
    "       'consultant','retailer','teacher','actress','acting','own','cleaning','agency','footballer',\n",
    "       'footballer','architect','architect','realtor','realtor','biomedical','duvets','genticist','project','graphic designer','graphic','orientator',\n",
    "       'vendor','preacher', 'builder' , 'writer', 'skilled','drummer','service','businesswoman','businessman','linguist','chef',\n",
    "       'artist','student','students','business woman','water treatment','freelance','geophysicist','brand','filmmaker','surveyor',\n",
    "       'locksmith','nurse','tailor','brand owner','painter','plumbing','shoemaker','graduate','cinematographer','truck','videographer',\n",
    "       'graphics','ui/ux','ui/ux','broker','economist','veterinarian','consultant','labourer', 'event','manager','sonographer',\n",
    "        'profession','marketing','stylist','translator','supplier','trainee','digital','marketer','geologist','planner','event',\n",
    "       'driver','butcherman','business man','artisan','physiotherapist','specialist','barber','scientist','driver']\n",
    "labour['Career'] = labour['Processed_Tweets'].apply(lambda x: ','.join([word for word in x.split() if word in (words)]))\n",
    "labour['Career']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcb573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stop_words and custom words to search for and apply in the Processed_tweets column into a new Career column\n",
    "stop = list(stopwords.words('english'))\n",
    "words= ['engineer', 'farmer','lawyer','manager','baker','caterer','student','painting','software','civil',\n",
    "      'engineer', 'project', 'manager', 'petroleum','making','soap', 'sailor', 'pilot', 'investment', 'dentist',\n",
    "       'software', 'developer', 'accountant','entrepreneur','entrepreneur','designer','designer', 'professional',\n",
    "        'printer', 'trader','paints','legal','freelance','nurse','surgeon','zoologist',\n",
    "      'optometrist','fashion','fashion','fashion designer','guitar','music', 'tech','startup','start-up',\n",
    "      'truck driver','driver','truck','owner','business','market','cook','cooking','pharmacist',\n",
    "       'electrician', 'mechanic', 'machinist','medical', 'doctor','banker','lecturer','lecturer','project manager',\n",
    "       'pharmacist','it', 'security', 'analyst', 'ethical', 'hackers','programmers',\n",
    "       'insurance', 'agent', 'human', 'capital', 'developer','hustler','photographer','craft','borehole', 'technician',\n",
    "       'educator','dealer','dealer','chemical','chemical','photography','business','service','marketer',\n",
    "       'cosmetics','clay','sculptor','clay sculptor','project','graphic designer','graphic','orientator',\n",
    "       'consultant','retailer','teacher','actress','acting','own','cleaning','agency','footballer',\n",
    "       'footballer','architect','architect','realtor','realtor','biomedical','duvets','genticist','project','graphic designer','graphic','orientator',\n",
    "       'vendor','preacher', 'builder' , 'writer', 'skilled','drummer','service','businesswoman','businessman','linguist','chef',\n",
    "       'artist','student','students','business woman','water treatment','freelance','geophysicist','brand','filmmaker','surveyor',\n",
    "       'locksmith','nurse','tailor','brand owner','painter','plumbing','shoemaker','graduate','cinematographer','truck','videographer',\n",
    "       'graphics','ui/ux','ui/ux','broker','economist','veterinarian','consultant','labourer', 'event','manager','sonographer',\n",
    "        'profession','marketing','stylist','translator','supplier','trainee','digital','marketer','geologist','planner','event',\n",
    "       'driver','butcherman','business man','artisan','physiotherapist','specialist','barber','scientist','driver']\n",
    "dignity['Career'] = dignity['Processed_Tweets'].apply(lambda x: ','.join([word for word in x.split() if word in (words)]))\n",
    "dignity['Career']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour.Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find null/empty values\n",
    "sum(labour['Career'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find null/empty values\n",
    "sum(dignity['Career'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings in Career column with Np.nan values\n",
    "labour.Career = labour['Career'].replace(r'^\\s*$', np.NaN, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd510c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings in Career column with Np.nan values\n",
    "dignity.Career = dignity['Career'].replace(r'^\\s*$', np.NaN, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find Career and replace with preferred name\n",
    "labour.loc[labour['Career'].str.contains('graduate,graduate',na=False), 'Career']= 'graduate'\n",
    "labour.loc[labour['Career'].str.contains('soap',na=False), 'Career']= 'soap maker'\n",
    "labour.loc[labour['Career'].str.contains('truck,driver',na=False), 'Career']= 'truck driver'\n",
    "labour.loc[labour['Career'].str.contains('marketer,owner',na=False), 'Career']= 'marketer'\n",
    "labour.loc[labour['Career'].str.contains('nurse',na=False), 'Career']='nurse'\n",
    "labour.loc[labour['Career'].str.contains('surgeon',na=False), 'Career']='surgeon'\n",
    "labour.loc[labour['Career'].str.contains('zoologist',na=False), 'Career']='zoologist'\n",
    "labour.loc[labour['Career'].str.contains('painter',na=False), 'Career']= 'painter'\n",
    "labour.loc[labour['Career'].str.contains('caterer',na=False), 'Career']= 'caterer'\n",
    "labour.loc[labour['Career'].str.contains('pharmacist',na=False), 'Career']= 'pharmacist'\n",
    "labour.loc[labour['Career'].str.contains('sales,representative',na=False), 'Career']= 'sales representative'\n",
    "labour.loc[labour['Career'].str.contains('hustler',na=False), 'Career']= 'hustler'\n",
    "labour.loc[labour['Career'].str.contains('student',na=False), 'Career']= 'student'\n",
    "labour.loc[labour['Career'].str.contains('painting',na=False), 'Career']= 'painter'\n",
    "labour.loc[labour['Career'].str.contains('business,farmer',na=False), 'Career'] ='farmer'\n",
    "labour.loc[labour['Career'].str.contains('tech,startup,service',na=False), 'Career']='tech startup'\n",
    "labour.loc[labour['Career'].str.contains('truck',na=False), 'Career'] ='truck driver'\n",
    "labour.loc[labour['Career'].str.contains('manager,marketing,manager,nurse,medical',na=False), 'Career']= 'nurse'\n",
    "labour.loc[labour['Career'].str.contains('medical',na=False), 'Career']='doctor'\n",
    "labour.loc[labour['Career'].str.contains('bioMedical',na=False), 'Career']='biomedical engineer'\n",
    "labour.loc[labour['Career'].str.contains('cooking,human',na=False), 'Career']='cook'\n",
    "labour.loc[labour['Career'].str.contains('writer,stylist',na=False), 'Career']='writer'\n",
    "labour.loc[labour['Career'].str.contains('stylist',na=False), 'Career']='stylist'\n",
    "labour.loc[labour['Career'].str.contains('tailor',na=False), 'Career']='tailor'\n",
    "labour.loc[labour['Career'].str.contains('realtor',na=False), 'Career']='realtor'\n",
    "labour.loc[labour['Career'].str.contains('fashion',na=False), 'Career']='fashion designer'\n",
    "labour.loc[labour['Career'].str.contains('insurance',na=False), 'Career']='insurance agent'\n",
    "labour.loc[labour['Career'].str.contains('vendor',na=False), 'Career']='vendor'\n",
    "labour.loc[labour['Career'].str.contains('event',na=False), 'Career']='event planner'\n",
    "labour.loc[labour['Career'].str.contains('graduate',na=False), 'Career']='graduate'\n",
    "labour.loc[labour['Career'].str.contains('video',na=False), 'Career']='videographer'\n",
    "labour.loc[labour['Career'].str.contains('photo',na=False), 'Career']='photographer'\n",
    "labour.loc[labour['Career'].str.contains('student',na=False), 'Career']='student'\n",
    "labour.loc[labour['Career'].str.contains('technician',na=False), 'Career']='technician'\n",
    "labour.loc[labour['Career'].str.contains('dealer',na=False), 'Career']='chemical dealer'\n",
    "labour.loc[labour['Career'].str.contains('chemical,engineer',na=False), 'Career']='engineer'\n",
    "labour.loc[labour['Career'].str.contains('labour',na=False), 'Career']='labourer'\n",
    "labour.loc[labour['Career'].str.contains('cleaning',na=False), 'Career']='cleaner'\n",
    "labour.loc[labour['Career'].str.contains('designer',na=False), 'Career']='designer'\n",
    "labour.loc[labour['Career'].str.contains('farmer',na=False), 'Career']='farmer'\n",
    "labour.loc[labour['Career'].str.contains('project',na=False), 'Career']='project manager'\n",
    "labour.loc[labour['Career'].str.contains('sculptor',na=False), 'Career']='sculptor'\n",
    "labour.loc[labour['Career'].str.contains('accountant',na=False), 'Career']='accountant'\n",
    "labour.loc[labour['Career'].str.contains('baker',na=False), 'Career']='baker'\n",
    "labour.loc[labour['Career'].str.contains('marketer',na=False), 'Career']='marketer'\n",
    "labour.loc[labour['Career'].str.contains('marketing',na=False), 'Career']='marketer'\n",
    "labour.loc[labour['Career'].str.contains('architect',na=False), 'Career']='architect'\n",
    "labour.loc[labour['Career'].str.contains('engineer',na=False), 'Career']='engineer'\n",
    "labour.loc[labour['Career'].str.contains('software',na=False), 'Career']= 'software engineer'\n",
    "labour.loc[labour['Career'].str.contains('civil',na=False), 'Career']= 'civil engineer'\n",
    "labour.loc[labour['Career'].str.contains('artist',na=False), 'Career']='artist'\n",
    "labour.loc[labour['Career'].str.contains('banker',na=False), 'Career']='banker'\n",
    "labour.loc[labour['Career'].str.contains('business',na=False), 'Career']='business'\n",
    "labour.loc[labour['Career'].str.contains('consultant',na=False), 'Career']='consultant'\n",
    "labour.loc[labour['Career'].str.contains('entrepreneur',na=False), 'Career']='entrepreneur'\n",
    "labour.loc[labour['Career'].str.contains('actress',na=False), 'Career']='actress'\n",
    "labour.loc[labour['Career'].str.contains('brand',na=False), 'Career']='brand owner'\n",
    "labour.loc[labour['Career'].str.contains('teacher',na=False), 'Career']='teacher'\n",
    "labour.loc[labour['Career'].str.contains('developer',na=False), 'Career']='developer'\n",
    "labour.loc[labour['Career'].str.contains('manager',na=False), 'Career']='manager'\n",
    "labour.loc[labour['Career'].str.contains('analyst',na=False), 'Career']='software analyst'\n",
    "labour.loc[labour['Career'].str.contains('translator',na=False), 'Career']='translator'\n",
    "labour.loc[labour['Career'].str.contains('professional',na=False), 'Career']='professional'\n",
    "labour.loc[labour['Career'].str.contains('printer',na=False), 'Career']='printer'\n",
    "labour.loc[labour['Career'].str.contains('printing',na=False), 'Career']='printer'\n",
    "labour.loc[labour['Career'].str.contains('trader',na=False), 'Career']='trader'\n",
    "labour.loc[labour['Career'].str.contains('trade',na=False), 'Career']='trader'\n",
    "labour.loc[labour['Career'].str.contains('paints',na=False), 'Career']='painter'\n",
    "labour.loc[labour['Career'].str.contains('legal',na=False), 'Career']='lawyer'\n",
    "labour.loc[labour['Career'].str.contains('freelance',na=False), 'Career']='freelancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the value counts\n",
    "labour.Career.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e93928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find Career and replace with preferred name\n",
    "dignity.loc[dignity['Career'].str.contains('graduate,graduate',na=False), 'Career']= 'graduate'\n",
    "dignity.loc[dignity['Career'].str.contains('truck,driver',na=False), 'Career']= 'truck driver'\n",
    "dignity.loc[dignity['Career'].str.contains('marketer,owner',na=False), 'Career']= 'marketer'\n",
    "dignity.loc[dignity['Career'].str.contains('painter',na=False), 'Career']= 'painter'\n",
    "dignity.loc[dignity['Career'].str.contains('student',na=False), 'Career']= 'student'\n",
    "dignity.loc[dignity['Career'].str.contains('nurse',na=False), 'Career']='nurse'\n",
    "dignity.loc[dignity['Career'].str.contains('surgeon',na=False), 'Career']='surgeon'\n",
    "dignity.loc[dignity['Career'].str.contains('zoologist',na=False), 'Career']='zoologist'\n",
    "dignity.loc[dignity['Career'].str.contains('pharmacist',na=False), 'Career']= 'pharmacist'\n",
    "dignity.loc[dignity['Career'].str.contains('painting',na=False), 'Career']= 'painter'\n",
    "dignity.loc[dignity['Career'].str.contains('sales,representative',na=False), 'Career']= 'sales representative'\n",
    "dignity.loc[dignity['Career'].str.contains('hustler',na=False), 'Career']= 'hustler'\n",
    "dignity.loc[dignity['Career'].str.contains('caterer',na=False), 'Career']= 'caterer'\n",
    "dignity.loc[dignity['Career'].str.contains('business,farmer',na=False), 'Career'] ='farmer'\n",
    "dignity.loc[dignity['Career'].str.contains('tech,startup,service',na=False), 'Career']='tech startup'\n",
    "dignity.loc[dignity['Career'].str.contains('truck',na=False), 'Career'] ='truck driver'\n",
    "dignity.loc[dignity['Career'].str.contains('manager,marketing,manager,nurse,medical',na=False), 'Career']= 'nurse'\n",
    "dignity.loc[dignity['Career'].str.contains('medical',na=False), 'Career']='doctor'\n",
    "dignity.loc[dignity['Career'].str.contains('bioMedical',na=False), 'Career']='biomedical engineer'\n",
    "dignity.loc[dignity['Career'].str.contains('cooking,human',na=False), 'Career']='cook'\n",
    "dignity.loc[dignity['Career'].str.contains('writer,stylist',na=False), 'Career']='writer'\n",
    "dignity.loc[dignity['Career'].str.contains('stylist',na=False), 'Career']='stylist'\n",
    "dignity.loc[dignity['Career'].str.contains('tailor',na=False), 'Career']='tailor'\n",
    "dignity.loc[dignity['Career'].str.contains('realtor',na=False), 'Career']='realtor'\n",
    "dignity.loc[dignity['Career'].str.contains('fashion',na=False), 'Career']='fashion designer'\n",
    "dignity.loc[dignity['Career'].str.contains('insurance',na=False), 'Career']='insurance agent'\n",
    "dignity.loc[dignity['Career'].str.contains('vendor',na=False), 'Career']='vendor'\n",
    "dignity.loc[dignity['Career'].str.contains('event',na=False), 'Career']='event planner'\n",
    "dignity.loc[dignity['Career'].str.contains('graduate',na=False), 'Career']='graduate'\n",
    "dignity.loc[dignity['Career'].str.contains('video',na=False), 'Career']='videographer'\n",
    "dignity.loc[dignity['Career'].str.contains('photo',na=False), 'Career']='photographer'\n",
    "dignity.loc[dignity['Career'].str.contains('student',na=False), 'Career']='student'\n",
    "dignity.loc[dignity['Career'].str.contains('technician',na=False), 'Career']='technician'\n",
    "dignity.loc[dignity['Career'].str.contains('dealer',na=False), 'Career']='chemical dealer'\n",
    "dignity.loc[dignity['Career'].str.contains('chemical,engineer',na=False), 'Career']='engineer'\n",
    "dignity.loc[dignity['Career'].str.contains('labour',na=False), 'Career']='labourer'\n",
    "dignity.loc[dignity['Career'].str.contains('cleaning',na=False), 'Career']='cleaner'\n",
    "dignity.loc[dignity['Career'].str.contains('designer',na=False), 'Career']='designer'\n",
    "dignity.loc[dignity['Career'].str.contains('farmer',na=False), 'Career']='farmer'\n",
    "dignity.loc[dignity['Career'].str.contains('project',na=False), 'Career']='project manager'\n",
    "dignity.loc[dignity['Career'].str.contains('sculptor',na=False), 'Career']='sculptor'\n",
    "dignity.loc[dignity['Career'].str.contains('accountant',na=False), 'Career']='accountant'\n",
    "dignity.loc[dignity['Career'].str.contains('baker',na=False), 'Career']='baker'\n",
    "dignity.loc[dignity['Career'].str.contains('marketer',na=False), 'Career']='marketer'\n",
    "dignity.loc[dignity['Career'].str.contains('marketing',na=False), 'Career']='marketer'\n",
    "dignity.loc[dignity['Career'].str.contains('architect',na=False), 'Career']='architect'\n",
    "dignity.loc[dignity['Career'].str.contains('engineer',na=False), 'Career']='engineer'\n",
    "dignity.loc[dignity['Career'].str.contains('software',na=False), 'Career']= 'software engineer'\n",
    "dignity.loc[dignity['Career'].str.contains('civil',na=False), 'Career']= 'civil engineer'\n",
    "dignity.loc[dignity['Career'].str.contains('artist',na=False), 'Career']='artist'\n",
    "dignity.loc[dignity['Career'].str.contains('banker',na=False), 'Career']='banker'\n",
    "dignity.loc[dignity['Career'].str.contains('business',na=False), 'Career']='business'\n",
    "dignity.loc[dignity['Career'].str.contains('consultant',na=False), 'Career']='consultant'\n",
    "dignity.loc[dignity['Career'].str.contains('entrepreneur',na=False), 'Career']='entrepreneur'\n",
    "dignity.loc[dignity['Career'].str.contains('actress',na=False), 'Career']='actress'\n",
    "dignity.loc[dignity['Career'].str.contains('brand',na=False), 'Career']='brand owner'\n",
    "dignity.loc[dignity['Career'].str.contains('teacher',na=False), 'Career']='teacher'\n",
    "dignity.loc[dignity['Career'].str.contains('developer',na=False), 'Career']='developer'\n",
    "dignity.loc[dignity['Career'].str.contains('manager',na=False), 'Career']='manager'\n",
    "dignity.loc[dignity['Career'].str.contains('analyst',na=False), 'Career']='software analyst'\n",
    "dignity.loc[dignity['Career'].str.contains('translator',na=False), 'Career']='translator'\n",
    "dignity.loc[dignity['Career'].str.contains('professional',na=False), 'Career']='professional'\n",
    "dignity.loc[dignity['Career'].str.contains('printer',na=False), 'Career']='printer'\n",
    "dignity.loc[dignity['Career'].str.contains('printing',na=False), 'Career']='printer'\n",
    "dignity.loc[dignity['Career'].str.contains('trader',na=False), 'Career']='trader'\n",
    "dignity.loc[dignity['Career'].str.contains('trade',na=False), 'Career']='trader'\n",
    "dignity.loc[dignity['Career'].str.contains('paints',na=False), 'Career']='painter'\n",
    "dignity.loc[dignity['Career'].str.contains('legal',na=False), 'Career']='lawyer'\n",
    "dignity.loc[dignity['Career'].str.contains('freelance',na=False), 'Career']='freelancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the value counts\n",
    "dignity.Career.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find states and replace with preferred name\n",
    "labour.loc[labour['Location'].str.contains('Lagos'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('lagos'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('lekki'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Abuja'), 'Location'] = 'Abuja'\n",
    "labour.loc[labour['Location'].str.contains('fct'), 'Location'] = 'Abuja'\n",
    "labour.loc[labour['Location'].str.contains('Federal'), 'Location'] = 'Abuja'\n",
    "labour.loc[labour['Location'].str.contains('abuja'), 'Location'] = 'Abuja'\n",
    "labour.loc[labour['Location'].str.contains('Ibadan'), 'Location'] = 'Oyo'\n",
    "labour.loc[labour['Location'].str.contains('Oyo'), 'Location'] = 'Oyo'\n",
    "labour.loc[labour['Location'].str.contains('Akwa'), 'Location'] = 'Akwa-Ibom'\n",
    "labour.loc[labour['Location'].str.contains('Osun'), 'Location'] = 'Osun'\n",
    "labour.loc[labour['Location'].str.contains('Bonny'), 'Location'] = 'Rivers'\n",
    "labour.loc[labour['Location'].str.contains('Lekki'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Ikorodu'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Ilorin'), 'Location'] = 'Kwara'\n",
    "labour.loc[labour['Location'].str.contains('Rumuigbo'), 'Location'] = 'Rivers'\n",
    "labour.loc[labour['Location'].str.contains('Lawanson'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Asaba'), 'Location'] = 'Delta'\n",
    "labour.loc[labour['Location'].str.contains('Uyo'), 'Location'] = 'Akwa-Ibom'\n",
    "labour.loc[labour['Location'].str.contains('Warri'), 'Location'] = 'Delta'\n",
    "labour.loc[labour['Location'].str.contains('Lasgidi'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Ikeja'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Abeokuta'), 'Location'] = 'Ogun'\n",
    "labour.loc[labour['Location'].str.contains('Lokoja'), 'Location'] = 'Kogi'\n",
    "labour.loc[labour['Location'].str.contains('Aba'), 'Location'] = 'Abia'\n",
    "labour.loc[labour['Location'].str.contains('Akure'), 'Location'] = 'Ondo'\n",
    "labour.loc[labour['Location'].str.contains('Port'), 'Location'] = 'Rivers'\n",
    "labour.loc[labour['Location'].str.contains('Abakaliki'), 'Location'] = 'Ebonyi'\n",
    "labour.loc[labour['Location'].str.contains('Enugu'), 'Location'] = 'Enugu'\n",
    "labour.loc[labour['Location'].str.contains('Awka'), 'Location'] = 'Anambra'\n",
    "labour.loc[labour['Location'].str.contains('Jos'), 'Location'] = 'Plateau'\n",
    "labour.loc[labour['Location'].str.contains('Abraka'), 'Location'] = 'Delta'\n",
    "labour.loc[labour['Location'].str.contains('Onitsha'), 'Location'] = 'Anambra'\n",
    "labour.loc[labour['Location'].str.contains('Owerri'), 'Location'] = 'Imo'\n",
    "labour.loc[labour['Location'].str.contains('ibadan'), 'Location'] = 'Oyo'\n",
    "labour.loc[labour['Location'].str.contains('port'), 'Location'] = 'Rivers'\n",
    "labour.loc[labour['Location'].str.contains('Ondo'), 'Location'] = 'Ondo'\n",
    "labour.loc[labour['Location'].str.contains('Victoria'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Ghana'), 'Location'] = 'Ghana'\n",
    "labour.loc[labour['Location'].str.contains('USA'), 'Location'] = 'USA'\n",
    "labour.loc[labour['Location'].str.contains('World'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Earth'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Global'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('NG'), 'Location'] = 'Nigeria'\n",
    "labour.loc[labour['Location'].str.contains('🌍'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('美国纽约州纽约曼哈顿华埠'), 'Location'] = 'China'\n",
    "labour.loc[labour['Location'].str.contains('Ado Ekiti'), 'Location'] = 'Ekiti'\n",
    "labour.loc[labour['Location'].str.contains('Yola'), 'Location'] = 'Adamawa'\n",
    "labour.loc[labour['Location'].str.contains('Yola'), 'Location'] = 'Adamawa'\n",
    "labour.loc[labour['Location'].str.contains('worldwide'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Kaduna'), 'Location'] = 'Kaduna'\n",
    "labour.loc[labour['Location'].str.contains('Makurdi'), 'Location'] = 'Benue'\n",
    "labour.loc[labour['Location'].str.contains('Here'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Near You'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Houston'), 'Location'] = 'USA'\n",
    "labour.loc[labour['Location'].str.contains('Toronto'), 'Location'] = 'Canada'\n",
    "labour.loc[labour['Location'].str.contains('Somewhere'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Yenagoa'), 'Location'] = 'Bayelsa'\n",
    "labour.loc[labour['Location'].str.contains('Benin'), 'Location'] = 'Edo'\n",
    "labour.loc[labour['Location'].str.contains('here'), 'Location'] = 'Everywhere'\n",
    "labour.loc[labour['Location'].str.contains('Atlanta'), 'Location'] = 'USA'\n",
    "labour.loc[labour['Location'].str.contains('Guangzhou'), 'Location'] = 'China'\n",
    "labour.loc[labour['Location'].str.contains('Chicago'), 'Location'] = 'USA'\n",
    "labour.loc[labour['Location'].str.contains('LAGOS'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('Calabar'), 'Location'] = 'Cross River'\n",
    "labour.loc[labour['Location'].str.contains('Osogbo'), 'Location'] = 'Osun'\n",
    "labour.loc[labour['Location'].str.contains('Umuahia'), 'Location'] = 'Abia'\n",
    "labour.loc[labour['Location'].str.contains('Anambra'), 'Location'] = 'Anambra'\n",
    "labour.loc[labour['Location'].str.contains('PORT'), 'Location'] = 'Rivers'\n",
    "labour.loc[labour['Location'].str.contains('Imo'), 'Location'] = 'Imo'\n",
    "labour.loc[labour['Location'].str.contains('yaba'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('owerri'), 'Location'] = 'Imo'\n",
    "labour.loc[labour['Location'].str.contains('FCT, ABUJA'), 'Location'] = 'Abuja'\n",
    "labour.loc[labour['Location'].str.contains('Adamawa'), 'Location'] = 'Adamawa'\n",
    "labour.loc[labour['Location'].str.contains('Badagry'), 'Location'] = 'Lagos'\n",
    "labour.loc[labour['Location'].str.contains('enugu'), 'Location'] = 'Enugu'\n",
    "labour.loc[labour['Location'].str.contains('oyo'), 'Location'] = 'Oyo'\n",
    "labour.loc[labour['Location'].str.contains('France'), 'Location'] = 'France'\n",
    "labour.loc[labour['Location'].str.contains('Montréal'), 'Location'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value counts\n",
    "labour.Location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045badad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find states and replace with preferred name\n",
    "dignity.loc[dignity['Location'].str.contains('Lagos'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('lagos'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('lekki'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Abuja'), 'Location'] = 'Abuja'\n",
    "dignity.loc[dignity['Location'].str.contains('fct'), 'Location'] = 'Abuja'\n",
    "dignity.loc[dignity['Location'].str.contains('Federal'), 'Location'] = 'Abuja'\n",
    "dignity.loc[dignity['Location'].str.contains('abuja'), 'Location'] = 'Abuja'\n",
    "dignity.loc[dignity['Location'].str.contains('Ibadan'), 'Location'] = 'Oyo'\n",
    "dignity.loc[dignity['Location'].str.contains('Oyo'), 'Location'] = 'Oyo'\n",
    "dignity.loc[dignity['Location'].str.contains('Akwa'), 'Location'] = 'Akwa-Ibom'\n",
    "dignity.loc[dignity['Location'].str.contains('Osun'), 'Location'] = 'Osun'\n",
    "dignity.loc[dignity['Location'].str.contains('Bonny'), 'Location'] = 'Rivers'\n",
    "dignity.loc[dignity['Location'].str.contains('Lekki'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Ikorodu'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Ilorin'), 'Location'] = 'Kwara'\n",
    "dignity.loc[dignity['Location'].str.contains('Rumuigbo'), 'Location'] = 'Rivers'\n",
    "dignity.loc[dignity['Location'].str.contains('Lawanson'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Asaba'), 'Location'] = 'Delta'\n",
    "dignity.loc[dignity['Location'].str.contains('Uyo'), 'Location'] = 'Akwa-Ibom'\n",
    "dignity.loc[dignity['Location'].str.contains('Warri'), 'Location'] = 'Delta'\n",
    "dignity.loc[dignity['Location'].str.contains('Lasgidi'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Ikeja'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Abeokuta'), 'Location'] = 'Ogun'\n",
    "dignity.loc[dignity['Location'].str.contains('Lokoja'), 'Location'] = 'Kogi'\n",
    "dignity.loc[dignity['Location'].str.contains('Aba'), 'Location'] = 'Abia'\n",
    "dignity.loc[dignity['Location'].str.contains('Akure'), 'Location'] = 'Ondo'\n",
    "dignity.loc[dignity['Location'].str.contains('Port'), 'Location'] = 'Rivers'\n",
    "dignity.loc[dignity['Location'].str.contains('Abakaliki'), 'Location'] = 'Ebonyi'\n",
    "dignity.loc[dignity['Location'].str.contains('Enugu'), 'Location'] = 'Enugu'\n",
    "dignity.loc[dignity['Location'].str.contains('Awka'), 'Location'] = 'Anambra'\n",
    "dignity.loc[dignity['Location'].str.contains('Jos'), 'Location'] = 'Plateau'\n",
    "dignity.loc[dignity['Location'].str.contains('Abraka'), 'Location'] = 'Delta'\n",
    "dignity.loc[dignity['Location'].str.contains('Onitsha'), 'Location'] = 'Anambra'\n",
    "dignity.loc[dignity['Location'].str.contains('Owerri'), 'Location'] = 'Imo'\n",
    "dignity.loc[dignity['Location'].str.contains('ibadan'), 'Location'] = 'Oyo'\n",
    "dignity.loc[dignity['Location'].str.contains('port'), 'Location'] = 'Rivers'\n",
    "dignity.loc[dignity['Location'].str.contains('Ondo'), 'Location'] = 'Ondo'\n",
    "dignity.loc[dignity['Location'].str.contains('Victoria'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Ghana'), 'Location'] = 'Ghana'\n",
    "dignity.loc[dignity['Location'].str.contains('USA'), 'Location'] = 'USA'\n",
    "dignity.loc[dignity['Location'].str.contains('World'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Earth'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Global'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('NG'), 'Location'] = 'Nigeria'\n",
    "dignity.loc[dignity['Location'].str.contains('🌍'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('美国纽约州纽约曼哈顿华埠'), 'Location'] = 'China'\n",
    "dignity.loc[dignity['Location'].str.contains('Ado Ekiti'), 'Location'] = 'Ekiti'\n",
    "dignity.loc[dignity['Location'].str.contains('Yola'), 'Location'] = 'Adamawa'\n",
    "dignity.loc[dignity['Location'].str.contains('Yola'), 'Location'] = 'Adamawa'\n",
    "dignity.loc[dignity['Location'].str.contains('worldwide'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Kaduna'), 'Location'] = 'Kaduna'\n",
    "dignity.loc[dignity['Location'].str.contains('Makurdi'), 'Location'] = 'Benue'\n",
    "dignity.loc[dignity['Location'].str.contains('Here'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Near You'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Houston'), 'Location'] = 'USA'\n",
    "dignity.loc[dignity['Location'].str.contains('Toronto'), 'Location'] = 'Canada'\n",
    "dignity.loc[dignity['Location'].str.contains('Somewhere'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Yenagoa'), 'Location'] = 'Bayelsa'\n",
    "dignity.loc[dignity['Location'].str.contains('Benin'), 'Location'] = 'Edo'\n",
    "dignity.loc[dignity['Location'].str.contains('here'), 'Location'] = 'Everywhere'\n",
    "dignity.loc[dignity['Location'].str.contains('Atlanta'), 'Location'] = 'USA'\n",
    "dignity.loc[dignity['Location'].str.contains('Guangzhou'), 'Location'] = 'China'\n",
    "dignity.loc[dignity['Location'].str.contains('Chicago'), 'Location'] = 'USA'\n",
    "dignity.loc[dignity['Location'].str.contains('LAGOS'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('Calabar'), 'Location'] = 'Cross River'\n",
    "dignity.loc[dignity['Location'].str.contains('Osogbo'), 'Location'] = 'Osun'\n",
    "dignity.loc[dignity['Location'].str.contains('Umuahia'), 'Location'] = 'Abia'\n",
    "dignity.loc[dignity['Location'].str.contains('Anambra'), 'Location'] = 'Anambra'\n",
    "dignity.loc[dignity['Location'].str.contains('PORT'), 'Location'] = 'Rivers'\n",
    "dignity.loc[dignity['Location'].str.contains('Imo'), 'Location'] = 'Imo'\n",
    "dignity.loc[dignity['Location'].str.contains('yaba'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('owerri'), 'Location'] = 'Imo'\n",
    "dignity.loc[dignity['Location'].str.contains('FCT, ABUJA'), 'Location'] = 'Abuja'\n",
    "dignity.loc[dignity['Location'].str.contains('Adamawa'), 'Location'] = 'Adamawa'\n",
    "dignity.loc[dignity['Location'].str.contains('Badagry'), 'Location'] = 'Lagos'\n",
    "dignity.loc[dignity['Location'].str.contains('enugu'), 'Location'] = 'Enugu'\n",
    "dignity.loc[dignity['Location'].str.contains('oyo'), 'Location'] = 'Oyo'\n",
    "dignity.loc[dignity['Location'].str.contains('France'), 'Location'] = 'France'\n",
    "dignity.loc[dignity['Location'].str.contains('Montréal'), 'Location'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value counts\n",
    "dignity.Location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings in Location column  with Np.nan values\n",
    "labour.Location = labour['Location'].replace(r'^\\s*$', np.NaN, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value counts\n",
    "labour.Location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings in Location column  with Np.nan values\n",
    "dignity.Location = dignity['Location'].replace(r'^\\s*$', np.NaN, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a33c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value counts\n",
    "dignity.Location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f16789",
   "metadata": {},
   "source": [
    "## Further Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate Date Crearted to different Year, Month and Time Column\n",
    "labour['Date'] = [d.date() for d in labour['Date Created']]\n",
    "labour['Time'] = [d.time() for d in labour['Date Created']]\n",
    "labour['Year'] = labour['Date Created'].dt.year\n",
    "labour['Month'] = labour['Date Created'].dt.month\n",
    "labour['Day'] = labour['Date Created'].dt.day\n",
    "labour['Hour'] = labour['Date Created'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate Date Crearted to different Year, Month and Time Column\n",
    "dignity['Date'] = [d.date() for d in dignity['Date Created']]\n",
    "dignity['Time'] = [d.time() for d in dignity['Date Created']]\n",
    "dignity['Year'] = dignity['Date Created'].dt.year\n",
    "dignity['Month'] = dignity['Date Created'].dt.month\n",
    "dignity['Day'] = dignity['Date Created'].dt.day\n",
    "dignity['Hour'] = dignity['Date Created'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace numerical month value to string\n",
    "labour.Month = labour['Date Created'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour.Hour.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace numerical month value to string\n",
    "dignity.Month = dignity['Date Created'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "dignity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make rows in Career column to title case\n",
    "labour.Career = labour['Career'].str.upper().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd98198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make rows in Career column to title case\n",
    "dignity.Career = dignity['Career'].str.upper().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467119c8",
   "metadata": {},
   "source": [
    "## Getting Latitudes and Longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c179d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour['Coordinates']=labour['Coordinates'].fillna('No Location') # Replace \"NaN\" values with \"No Location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb167f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dignity['Coordinates']=dignity['Coordinates'].fillna('No Location') # Replace \"NaN\" values with \"No Location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47971ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate Coordinate Columns to individual Latitude and Longitude in labour data\n",
    "labour['Geo'] = labour['Coordinates'].astype('string')\n",
    "a=labour['Geo'].astype(str).str.split(expand=True)\n",
    "a.columns = ['a', 'Longitude','c','Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate Coordinate Columns to individual Latitude and Longitude in dignity data\n",
    "dignity['Geo'] = dignity['Coordinates'].astype('string')\n",
    "b=dignity['Geo'].astype(str).str.split(expand=True)\n",
    "b.columns = ['a', 'Longitude','c','Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour =  pd.concat([labour,a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dignity =  pd.concat([dignity,b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738528b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns\n",
    "labour.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "cols=['Date Created','Processed_Tweets','Geo','a','c']\n",
    "labour=labour.drop(columns=cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cf1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns\n",
    "dignity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00904cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "cols=['Date Created','Processed_Tweets','Geo','a','c']\n",
    "dignity=dignity.drop(columns=cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace location with Np.nan values in Labour.Longitude column\n",
    "labour.Longitude= labour['Longitude'].replace('Location',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfe03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split , with values in Labour.Longitude column\n",
    "labour['Longitude']=labour['Longitude'].str.split(',', n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split } with values in Labour.Latitude column\n",
    "labour['Latitude']=labour['Latitude'].str.split('}', n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace location with Np.nan values in dignity.Longitude column\n",
    "dignity.Longitude= dignity['Longitude'].replace('Location',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87faaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split , with values in Labour.Longitude column\n",
    "dignity['Longitude']=dignity['Longitude'].str.split(',', n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split } with values in dignity.Latitude column\n",
    "dignity['Latitude']=dignity['Latitude'].str.split('}', n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dignity.Longitude.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69916cec",
   "metadata": {},
   "source": [
    "## SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to clean the tweets in labour and dignity dataframe\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "stopword=set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 'clean' to the labour tweet data\n",
    "labour[\"Tweet\"] = labour[\"Tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e30421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 'clean' to the dignity tweet data\n",
    "dignity[\"Tweet\"] = dignity[\"Tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25664ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentiment scores from the labour data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "labour[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in labour[\"Tweet\"]]\n",
    "labour[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in labour[\"Tweet\"]]\n",
    "labour[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in labour[\"Tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c447a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1bb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentiment scores from the dignity data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "dignity[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in dignity[\"Tweet\"]]\n",
    "dignity[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in dignity[\"Tweet\"]]\n",
    "dignity[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in dignity[\"Tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dignity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to obtain Subjectivity Score\n",
    "def getSubjectivity(tweet):\n",
    "    return TextBlob(tweet).sentiment.subjectivity\n",
    "\n",
    "# Create function to obtain Polarity Score\n",
    "def getPolarity(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "# Create function to obtain Sentiment category\n",
    "def getSentimentTextBlob(polarity):\n",
    "    if polarity < 0:\n",
    "        return \"Negative\"\n",
    "    elif polarity == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all functions above to respective columns in labour data\n",
    "labour['Subjectivity']=labour['Tweet'].apply(getSubjectivity)\n",
    "labour['Polarity']=labour['Tweet'].apply(getPolarity)\n",
    "labour['Sentiment']=labour['Polarity'].apply(getSentimentTextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27508e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all functions above to respective columns in dignity data\n",
    "dignity['Subjectivity']=dignity['Tweet'].apply(getSubjectivity)\n",
    "dignity['Polarity']=dignity['Tweet'].apply(getPolarity)\n",
    "dignity['Sentiment']=dignity['Polarity'].apply(getSentimentTextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See quick results of the Sentiment Analysis in labour data\n",
    "labour['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See quick results of the Sentiment Analysis in dignity data\n",
    "dignity['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593054da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write labour to csv file\n",
    "labour.to_csv('labourfinal.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdde7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write dignity to csv file\n",
    "dignity.to_csv('dignityfinal.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check labour shape\n",
    "labour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a705dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dignity shape\n",
    "dignity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d0e38",
   "metadata": {},
   "source": [
    "## Concatenate all data to one final variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate both datasets\n",
    "lab_dig = pd.concat([labour,dignity], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa78426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check concat data shape\n",
    "lab_dig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See quick results of the Sentiment Analysis concat dat\n",
    "lab_dig['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833dd4f",
   "metadata": {},
   "source": [
    "## Write to CSV for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write concat data to csv file\n",
    "lab_dig.to_csv('labour_dignity_final.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
